{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyautogui\n",
    "!pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 中ボタンを押し下げる（マウスダウン）\n",
    "pyautogui.mouseDown(button='middle')\n",
    "\n",
    "# 3秒待つ\n",
    "pyautogui.sleep(3)\n",
    "\n",
    "# 中ボタンを離す（マウスアップ）\n",
    "pyautogui.mouseUp(button='middle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Value, Array\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "import pyautogui\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "class GaussianFilter:\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "        self.prev_value = None\n",
    "\n",
    "    def filter(self, value):\n",
    "        if self.prev_value is None:\n",
    "            self.prev_value = value\n",
    "            return value\n",
    "        else:\n",
    "            self.prev_value = self.alpha * value + (1 - self.alpha) * self.prev_value \n",
    "            return self.prev_value\n",
    "        \n",
    "class AdaptiveGaussianFilter:\n",
    "    def __init__(self, alpha_min, alpha_max, diff_min, diff_max):\n",
    "        self.alpha_min = alpha_min\n",
    "        self.alpha_max = alpha_max\n",
    "        self.diff_min = diff_min\n",
    "        self.diff_max = diff_max\n",
    "        self.prev_value = None\n",
    "\n",
    "    def filter(self, value):\n",
    "        if self.prev_value is None:\n",
    "            self.prev_value = value\n",
    "            return value\n",
    "        else:\n",
    "            diff = np.linalg.norm(value - self.prev_value)\n",
    "            alpha = map_and_trim(diff, self.diff_min, self.diff_max, self.alpha_min, self.alpha_max)\n",
    "            self.prev_value = alpha * value + (1 - alpha) * self.prev_value\n",
    "            self.prev_diff = diff\n",
    "            return self.prev_value\n",
    "            \n",
    "class AlphaBetaFilter:\n",
    "    def __init__(self, alpha, beta, dt):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.dt = dt\n",
    "        self.x_hat = np.array([0.0])\n",
    "        self.v_hat = np.array([0.0])\n",
    "\n",
    "    def filter(self, x):\n",
    "        if np.all(self.x_hat == 0) and np.all(self.v_hat == 0):\n",
    "            self.x_hat = x\n",
    "            self.v_hat = np.zeros_like(x)\n",
    "            return x\n",
    "        else:\n",
    "            r = x - self.x_hat\n",
    "            self.x_hat += self.v_hat * self.dt + self.alpha * r\n",
    "            self.v_hat += (self.beta * r) / self.dt\n",
    "            return self.x_hat\n",
    "\n",
    "class MovingAverageFilter:\n",
    "    def __init__(self, window_size):\n",
    "        self.window_size = window_size\n",
    "        self.values = []\n",
    "\n",
    "    def filter(self, value):\n",
    "        self.values.append(value)\n",
    "        if len(self.values) > self.window_size:\n",
    "            self.values.pop(0)\n",
    "        return sum(self.values) / len(self.values)\n",
    "    \n",
    "def map_and_trim(value, in_min, in_max, out_min, out_max):\n",
    "    # 入力範囲に基づいて値を正規化\n",
    "    value_normalized = (value - in_min) / (in_max - in_min)\n",
    "\n",
    "    # 正規化された値を出力範囲にマップ\n",
    "    value_mapped = value_normalized * (out_max - out_min) + out_min\n",
    "\n",
    "    # 値を出力範囲内にトリム\n",
    "    value_trimmed = max(min(value_mapped, out_max), out_min)\n",
    "\n",
    "    return value_trimmed\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh()\n",
    "\n",
    "def count_cameras():\n",
    "    n = 0\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            cap = cv2.VideoCapture(i)\n",
    "            if cap is None or not cap.isOpened():\n",
    "                break\n",
    "            cap.release()\n",
    "            n += 1\n",
    "        except:\n",
    "            break\n",
    "    return n\n",
    "\n",
    "camera_index = 0\n",
    "camera_count = count_cameras()\n",
    "\n",
    "cap = cv2.VideoCapture(camera_index)\n",
    "\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        change_camera()\n",
    "def change_camera():\n",
    "    global cap, camera_index, camera_count\n",
    "    # カメラのインデックスを切り替える\n",
    "    cap.release()\n",
    "    camera_index = (camera_index + 1) % camera_count\n",
    "    cap = cv2.VideoCapture(camera_index)\n",
    "\n",
    "cv2.namedWindow('MediaPipe FaceMesh')\n",
    "cv2.setMouseCallback('MediaPipe FaceMesh', mouse_callback)\n",
    "\n",
    "mouth_open = False\n",
    "# booleanのValue\n",
    "tracking = Value('b', False)\n",
    "# \n",
    "target = Array('f', [0.0, 0.0])\n",
    "\n",
    "\n",
    "pyautogui.FAILSAFE = False\n",
    "\n",
    "# Processで動作するフレームループ\n",
    "def frame_loop(tracking, target):\n",
    "    try:\n",
    "        # filter = GaussianFilter(0.1)\n",
    "        filter = AdaptiveGaussianFilter(0.01, 0.2, 30, 200)\n",
    "        # filter = AlphaBetaFilter(0.05, 0.005, 0.03)\n",
    "        # filter = MovingAverageFilter(10)\n",
    "        \n",
    "        print_to_file('tracking start')\n",
    "        while tracking.value:\n",
    "            print_to_file('tracking')\n",
    "            filterd = filter.filter(np.array([target[0], target[1]]))\n",
    "            x_pos = filterd[0]\n",
    "            y_pos = filterd[1]\n",
    "\n",
    "            pyautogui.moveTo(x_pos, y_pos)\n",
    "\n",
    "            # 60fpsで待機\n",
    "            time.sleep(2)\n",
    "    except Exception as e:\n",
    "        print_to_file(e)\n",
    "        tracking.value = False\n",
    "\n",
    "def print_to_file(s):\n",
    "    with open('output.txt', 'a') as f:\n",
    "        f.write(s)\n",
    "\n",
    "print_to_file('test')\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # BGRからRGBに変換\n",
    "        rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(rgb_image)\n",
    "        # 塗りつぶし\n",
    "        cv2.rectangle(frame, (0, 0), (frame.shape[1], frame.shape[0]), (0, 0, 0), -1)\n",
    "\n",
    "        if results.multi_face_landmarks is not None:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                for id, lm in enumerate(face_landmarks.landmark):\n",
    "                    # 各ランドマークの座標を取得\n",
    "                    h, w, c = frame.shape\n",
    "                    x, y = int(lm.x * w), int(lm.y * h)\n",
    "                    # ランドマークを描画\n",
    "                    cv2.circle(frame, (x, y), 1, (0, 255, 0), 1)\n",
    "                    \n",
    "\n",
    "                # 口の開きが口の幅の20%以上のときに口が開いていると判定\n",
    "                # 口の幅を取得 \n",
    "                mouth_width = abs(face_landmarks.landmark[308].x - face_landmarks.landmark[78].x)\n",
    "                # 口の開きを取得\n",
    "                mouth_height = abs(face_landmarks.landmark[14].y - face_landmarks.landmark[13].y)\n",
    "                open = mouth_height > mouth_width * 0.2\n",
    "                close = mouth_height <= mouth_width * 0.1\n",
    "                # 口が閉じた状態から口が開いたときに中ボタンをダウン\n",
    "                if open and not mouth_open:\n",
    "                    pyautogui.mouseDown(button='middle')\n",
    "                    # print('mouth open')\n",
    "                    mouth_open = True\n",
    "                # 口が開いた状態から口が閉じたときに中ボタンをアップ\n",
    "                if close and mouth_open:\n",
    "                    pyautogui.mouseUp(button='middle')\n",
    "                    # print('mouth close')\n",
    "                    mouth_open = False\n",
    "\n",
    "                # 顔の向きを取得\n",
    "                face_nose = np.array([face_landmarks.landmark[6].x, face_landmarks.landmark[6].y, face_landmarks.landmark[6].z])\n",
    "                face_right = np.array([face_landmarks.landmark[127].x, face_landmarks.landmark[127].y, face_landmarks.landmark[127].z])\n",
    "                face_left = np.array([face_landmarks.landmark[356].x , face_landmarks.landmark[356].y, face_landmarks.landmark[356].z])\n",
    "                face_center = (face_right + face_left) / 2\n",
    "                face_front = face_nose - face_center\n",
    "                face_front_normarized = face_front / face_front[2]\n",
    "                x_pos = map_and_trim(face_front_normarized[0], -0.4, 0.4, 0, pyautogui.size()[0])\n",
    "                y_pos = map_and_trim(face_front_normarized[1], -0.25, 0.25, 0, pyautogui.size()[1])\n",
    "                target[0]=x_pos\n",
    "                target[1]=y_pos\n",
    "\n",
    "                break\n",
    "\n",
    "        # 左右反転\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        # デバッグ表示\n",
    "        cv2.putText(frame, f'Camera: {camera_index}', (50, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "        if results.multi_face_landmarks is not None: \n",
    "            cv2.putText(frame, f'{face_nose}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(frame, f'{face_center}', (50, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(frame, f'{face_front_normarized}', (50, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(frame, f'{x_pos} {y_pos}', (50, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "        # 画面表示\n",
    "        cv2.imshow('MediaPipe FaceMesh', frame)\n",
    "        \n",
    "        # キー入力\n",
    "        key = cv2.waitKey(5)\n",
    "        # Cでカメラ切り替え\n",
    "        if key & 0xFF == ord('c'):\n",
    "            change_camera()\n",
    "        # spaceでトラッキング開始\n",
    "        if key & 0xFF == 32:\n",
    "            tracking.value = not tracking.value\n",
    "            if tracking.value:\n",
    "                # Threadでフレームループを開始\n",
    "                with concurrent.futures.ProcessPoolExecutor(max_workers=1) as executor:\n",
    "                    executor.submit(frame_loop, tracking, target)\n",
    "                print('tracking started')\n",
    "\n",
    "        # esc or Qで終了\n",
    "        if key & 0xFF == 27 or key & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Value, Array\n",
    "import multiprocessing\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "import pyautogui\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "class GaussianFilter:\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "        self.prev_value = None\n",
    "\n",
    "    def filter(self, value):\n",
    "        if self.prev_value is None:\n",
    "            self.prev_value = value\n",
    "            return value\n",
    "        else:\n",
    "            self.prev_value = self.alpha * value + (1 - self.alpha) * self.prev_value \n",
    "            return self.prev_value\n",
    "        \n",
    "class AdaptiveGaussianFilter:\n",
    "    def __init__(self, alpha_min, alpha_max, diff_min, diff_max):\n",
    "        self.alpha_min = alpha_min\n",
    "        self.alpha_max = alpha_max\n",
    "        self.diff_min = diff_min\n",
    "        self.diff_max = diff_max\n",
    "        self.prev_value = None\n",
    "\n",
    "    def filter(self, value):\n",
    "        if self.prev_value is None:\n",
    "            self.prev_value = value\n",
    "            return value\n",
    "        else:\n",
    "            diff = np.linalg.norm(value - self.prev_value)\n",
    "            alpha = map_and_trim(diff, self.diff_min, self.diff_max, self.alpha_min, self.alpha_max)\n",
    "            self.prev_value = alpha * value + (1 - alpha) * self.prev_value\n",
    "            self.prev_diff = diff\n",
    "            return self.prev_value\n",
    "            \n",
    "class AlphaBetaFilter:\n",
    "    def __init__(self, alpha, beta, dt):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.dt = dt\n",
    "        self.x_hat = np.array([0.0])\n",
    "        self.v_hat = np.array([0.0])\n",
    "\n",
    "    def filter(self, x):\n",
    "        if np.all(self.x_hat == 0) and np.all(self.v_hat == 0):\n",
    "            self.x_hat = x\n",
    "            self.v_hat = np.zeros_like(x)\n",
    "            return x\n",
    "        else:\n",
    "            r = x - self.x_hat\n",
    "            self.x_hat += self.v_hat * self.dt + self.alpha * r\n",
    "            self.v_hat += (self.beta * r) / self.dt\n",
    "            return self.x_hat\n",
    "\n",
    "class MovingAverageFilter:\n",
    "    def __init__(self, window_size):\n",
    "        self.window_size = window_size\n",
    "        self.values = []\n",
    "\n",
    "    def filter(self, value):\n",
    "        self.values.append(value)\n",
    "        if len(self.values) > self.window_size:\n",
    "            self.values.pop(0)\n",
    "        return sum(self.values) / len(self.values)\n",
    "    \n",
    "def map_and_trim(value, in_min, in_max, out_min, out_max):\n",
    "    # 入力範囲に基づいて値を正規化\n",
    "    value_normalized = (value - in_min) / (in_max - in_min)\n",
    "\n",
    "    # 正規化された値を出力範囲にマップ\n",
    "    value_mapped = value_normalized * (out_max - out_min) + out_min\n",
    "\n",
    "    # 値を出力範囲内にトリム\n",
    "    value_trimmed = max(min(value_mapped, out_max), out_min)\n",
    "\n",
    "    return value_trimmed\n",
    "\n",
    "\n",
    "\n",
    "def count_cameras():\n",
    "    n = 0\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            cap = cv2.VideoCapture(i)\n",
    "            if cap is None or not cap.isOpened():\n",
    "                break\n",
    "            cap.release()\n",
    "            n += 1\n",
    "        except:\n",
    "            break\n",
    "    return n\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        change_camera()\n",
    "def change_camera():\n",
    "    global cap, camera_index, camera_count\n",
    "    # カメラのインデックスを切り替える\n",
    "    cap.release()\n",
    "    camera_index = (camera_index + 1) % camera_count\n",
    "    cap = cv2.VideoCapture(camera_index)\n",
    "\n",
    "# Processで動作するフレームループ\n",
    "def frame_loop(tracking, target):\n",
    "    fps = 60\n",
    "    try:\n",
    "        # filter = GaussianFilter(1 / fps)\n",
    "        filter = AdaptiveGaussianFilter(0.5 / fps, 10 / fps, 30, 200)\n",
    "        # filter = AlphaBetaFilter(0.05, 0.005, 0.03)\n",
    "        # filter = MovingAverageFilter(10)\n",
    "        \n",
    "        print('tracking start')\n",
    "        while tracking.value:\n",
    "        # for _ in range(5):\n",
    "            # print(f'tracking {tracking.value} {target}')\n",
    "            filterd = filter.filter(np.array([target[0], target[1]]))\n",
    "            x_pos = filterd[0]\n",
    "            y_pos = filterd[1]\n",
    "\n",
    "            pyautogui.moveTo(x_pos, y_pos)\n",
    "\n",
    "            # 60fpsで待機\n",
    "            time.sleep(1 / fps)\n",
    "        print('tracking end')\n",
    "\n",
    "    except Exception as e:\n",
    "        print('error' + e)\n",
    "        tracking.value = False\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mp_face_mesh = mp.solutions.face_mesh\n",
    "    face_mesh = mp_face_mesh.FaceMesh()\n",
    "    camera_index = 0\n",
    "    camera_count = count_cameras()\n",
    "    cv2.namedWindow('MediaPipe FaceMesh')\n",
    "    cv2.setMouseCallback('MediaPipe FaceMesh', mouse_callback)\n",
    "    cap = cv2.VideoCapture(camera_index)\n",
    "    mouth_open = False\n",
    "\n",
    "    # データ共有用のマネージャー\n",
    "    manager = multiprocessing.Manager()\n",
    "    # トラッキングフラグ\n",
    "    tracking = manager.Value('b', False)\n",
    "    # ターゲット座標\n",
    "    target = manager.list([0.0, 0.0])\n",
    "\n",
    "    executor = None\n",
    "\n",
    "    pyautogui.FAILSAFE = False\n",
    "\n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # BGRからRGBに変換\n",
    "            rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = face_mesh.process(rgb_image)\n",
    "            # 塗りつぶし\n",
    "            cv2.rectangle(frame, (0, 0), (frame.shape[1], frame.shape[0]), (0, 0, 0), -1)\n",
    "\n",
    "            if results.multi_face_landmarks is not None:\n",
    "                for face_landmarks in results.multi_face_landmarks:\n",
    "                    for id, lm in enumerate(face_landmarks.landmark):\n",
    "                        # 各ランドマークの座標を取得\n",
    "                        h, w, c = frame.shape\n",
    "                        x, y = int(lm.x * w), int(lm.y * h)\n",
    "                        # ランドマークを描画\n",
    "                        cv2.circle(frame, (x, y), 1, (0, 255, 0), 1)\n",
    "                        \n",
    "\n",
    "                    # 口の開きが口の幅の20%以上のときに口が開いていると判定\n",
    "                    # 口の幅を取得 \n",
    "                    mouth_width = abs(face_landmarks.landmark[308].x - face_landmarks.landmark[78].x)\n",
    "                    # 口の開きを取得\n",
    "                    mouth_height = abs(face_landmarks.landmark[14].y - face_landmarks.landmark[13].y)\n",
    "                    open = mouth_height > mouth_width * 0.2\n",
    "                    close = mouth_height <= mouth_width * 0.1\n",
    "                    # 口が閉じた状態から口が開いたときに中ボタンをダウン\n",
    "                    if open and not mouth_open:\n",
    "                        pyautogui.mouseDown(button='middle')\n",
    "                        # print('mouth open')\n",
    "                        mouth_open = True\n",
    "                    # 口が開いた状態から口が閉じたときに中ボタンをアップ\n",
    "                    if close and mouth_open:\n",
    "                        pyautogui.mouseUp(button='middle')\n",
    "                        # print('mouth close')\n",
    "                        mouth_open = False\n",
    "\n",
    "                    # 顔の向きを取得\n",
    "                    face_nose = np.array([face_landmarks.landmark[6].x, face_landmarks.landmark[6].y, face_landmarks.landmark[6].z])\n",
    "                    face_right = np.array([face_landmarks.landmark[127].x, face_landmarks.landmark[127].y, face_landmarks.landmark[127].z])\n",
    "                    face_left = np.array([face_landmarks.landmark[356].x , face_landmarks.landmark[356].y, face_landmarks.landmark[356].z])\n",
    "                    face_center = (face_right + face_left) / 2\n",
    "                    face_front = face_nose - face_center\n",
    "                    face_front_normarized = face_front / face_front[2]\n",
    "                    x_pos = map_and_trim(face_front_normarized[0], -0.38, 0.38, 0, pyautogui.size()[0])\n",
    "                    y_pos = map_and_trim(-face_front_normarized[1], -0.22, 0.22, 0, pyautogui.size()[1])\n",
    "                    target[0]=x_pos\n",
    "                    target[1]=y_pos\n",
    "\n",
    "                    break\n",
    "\n",
    "            # 左右反転\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            # デバッグ表示\n",
    "            cv2.putText(frame, f'Camera: {camera_index}', (50, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "            if results.multi_face_landmarks is not None: \n",
    "                cv2.putText(frame, f'{face_nose}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(frame, f'{face_center}', (50, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(frame, f'{face_front_normarized}', (50, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "                cv2.putText(frame, f'{x_pos} {y_pos}', (50, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "            # 画面表示\n",
    "            cv2.imshow('MediaPipe FaceMesh', frame)\n",
    "            \n",
    "            # キー入力\n",
    "            key = cv2.waitKey(5)\n",
    "            # Cでカメラ切り替え\n",
    "            if key & 0xFF == ord('c'):\n",
    "                change_camera()\n",
    "            # spaceでトラッキング開始\n",
    "            if key & 0xFF == 32:\n",
    "                tracking.value = not tracking.value\n",
    "                if tracking.value:\n",
    "                    # Threadでフレームループを開始\n",
    "                    if executor is not None:\n",
    "                        executor.shutdown()\n",
    "                    executor = concurrent.futures.ProcessPoolExecutor(max_workers=1)\n",
    "                    executor.submit(frame_loop, tracking, target)\n",
    "                    print('tracking started')\n",
    "\n",
    "            # esc or Qで終了\n",
    "            if key & 0xFF == 27 or key & 0xFF == ord('q'):\n",
    "                break\n",
    "            time.sleep(1 / 5)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    tracking.value = False\n",
    "\n",
    "    if executor is not None:\n",
    "        executor.shutdown()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "import time\n",
    "import random\n",
    "\n",
    "def worker(idx, n, a):\n",
    "    for _ in range(5):\n",
    "        n.value = random.random()\n",
    "        print(f'Updated value {idx}: {n.value}')\n",
    "        for i in range(len(a)):\n",
    "            a[i] = random.randint(1, 10)\n",
    "        print(f'Updated array {idx}: {list(a)}')\n",
    "        time.sleep(random.randint(1, 3))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with multiprocessing.Manager() as manager:\n",
    "        num = manager.Value('d', 0.0)\n",
    "        arr = manager.list(range(10))\n",
    "\n",
    "        with concurrent.futures.ProcessPoolExecutor(max_workers=3) as executor:\n",
    "            executor.submit(worker, 1, num, arr)\n",
    "            executor.submit(worker, 2, num, arr)\n",
    "            executor.submit(worker, 3, num, arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogui",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
